{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910072d5-680d-4300-ad43-e8d5e6f15077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import randint, uniform\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b3d65-0269-476a-983d-47ca2860254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# SE Block：引入 external_var 融合进注意力机制\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, external_dim=0):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.external_dim = external_dim\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(in_channels + external_dim, in_channels // reduction_ratio)\n",
    "        self.fc2 = nn.Linear(in_channels // reduction_ratio, in_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, external_var=None):\n",
    "        batch_size, channels, _, _ = x.size()\n",
    "        squeeze = self.global_avg_pool(x).view(batch_size, channels)\n",
    "        \n",
    "        if self.external_dim > 0 and external_var is not None:\n",
    "            squeeze = torch.cat((squeeze, external_var), dim=1)\n",
    "        \n",
    "        excitation = F.relu(self.fc1(squeeze))\n",
    "        excitation = self.sigmoid(self.fc2(excitation)).view(batch_size, channels, 1, 1)\n",
    "        return x * excitation\n",
    "\n",
    "\n",
    "# BottleNeck 模块：支持传递 external_var\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, reduction_ratio=16, use_se=True, external_dim=0):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        mid_channels = out_channels // 4\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.se = SEBlock(out_channels, reduction_ratio, external_dim) if use_se else nn.Identity()\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x, external_var=None):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = self.se(out, external_var)\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "# 主 SE-ResNet 网络结构\n",
    "class SEResNetRS(nn.Module):\n",
    "    def __init__(self, num_blocks=[2, 2, 2, 2], num_classes=1, external_dim=8):\n",
    "        super(SEResNetRS, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.external_dim = external_dim\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1, padding=1, bias=False)  # 输入通道为10\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(64, 64, num_blocks[1], stride=1)\n",
    "        self.layer3 = self._make_layer(64, 64, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(64, 64, num_blocks[3], stride=2)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 + external_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(BottleNeck(in_channels, out_channels, stride, external_dim=self.external_dim))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(BottleNeck(out_channels, out_channels, stride=1, external_dim=self.external_dim))\n",
    "        return nn.ModuleList(layers)\n",
    "\n",
    "    def forward_layer(self, layer_blocks, x, external_var):\n",
    "        for block in layer_blocks:\n",
    "            x = block(x, external_var)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, external_var):\n",
    "        x = x.permute(0, 3, 1, 2)  # 转为 [batch, channel=10, H=30, W=12]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        x = self.forward_layer(self.layer1, x, external_var)\n",
    "        x = self.forward_layer(self.layer2, x, external_var)\n",
    "        x = self.forward_layer(self.layer3, x, external_var)\n",
    "        x = self.forward_layer(self.layer4, x, external_var)\n",
    "\n",
    "        x = self.global_pool(x).view(x.size(0), -1)\n",
    "        combined = torch.cat((x, external_var), dim=1)\n",
    "        \n",
    "        x = F.relu(self.fc1(combined))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        out = self.fc3(x)\n",
    "        return out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
